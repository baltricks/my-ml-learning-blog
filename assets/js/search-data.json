{
  
    
        "post0": {
            "title": "Next",
            "content": "Drivetrain Approach . Defined objective (What outcome am I trying to achieve?) | Levers (What actions can I take? What inputs can we control?) | Data (What inputs can I collect?) | Models (How the levers influence the objective) | . Other Notes from Chapter 2 . one way to solve a particular problem with deep learning may or may not work with similiar looking problems | for good results it’s necessary to understand the constraints and capabilities of deep learning (don’t over- or underestimate them) | start many small projects, do them end-to-end - that lets the experience grow | .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/2022/01/01/next.html",
            "relUrl": "/2022/01/01/next.html",
            "date": " • Jan 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "My first practice with an image classifier (using fastbook and fastai), Part I",
            "content": "Which problem to solve . For my very first practice I followed the book (Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard &amp; Sylvain Gugger) and choose the bear image classifier as my first objective. . Starting with the input data and Google Colab . I used the DuckDuckGo search engine to find proper images in 3 categories as input data and stored them in the subfolders ‘black’, ‘grizzly’ and ‘teddy’. Then I created a new notebook with Google Colab (stored in Google Drive) and set the runtime to GPU. I copied my input data into a data folder on my drive and checked the input path with: . !ls drive/MyDrive/data/images/bears . and after installing and setting up fastbook . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . I also checked the mounted drive . !ls gdrive/MyDrive/data/images/bears . Before continuing let me show the imports I finally needed in my training notebook: . from fastbook import get_image_files, verify_images, Path, DataBlock, ImageBlock, CategoryBlock from fastbook import RandomSplitter, parent_label, Resize, ResizeMethod, RandomResizedCrop, aug_transforms from fastbook import cnn_learner, resnet18, error_rate, load_learner from fastbook import ClassificationInterpretation from fastai.vision.widgets import ImageClassifierCleaner, widgets, PILImage, VBox . Next step was to set my path variable and get the images . path = &#39;gdrive/MyDrive/data/images/bears&#39; fns = get_image_files(path) . After verifying the images and unlinking the failed ones . failed = verify_images(fns) failed.map(Path.unlink) . there were 495 images (in 3 categories) left. . Training a model . First I made some specifications about the input data of the training process: . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . This means that . predictions should be made from images (the independent variable) to categories (the dependent variable) | the items should be taken by the get_image_files function (which is taking a path as argument) | the data set should be splitted randomly into a training and validation set (20% of the data for the validation set; randomly, but always the same sets) | the labeling of the dependent variable (the categories, the y-value) should come from the folder name | and all items (images) should be transformed - here resized - to the same size of 128px | . Then I set the input path and got the data loaders: . dls = bears.dataloaders(path) . Before starting the training I played around with some transformations available for . images (resizing with different methods) and | batches of images (random image variations, the data augmentation) and watched the results printed with the show_batch function of the dataloaders (dls.train for the training set and dls.valid for the validation set). | . Then I followed the recommendation and made this settings: . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . I created the learner: . learn = cnn_learner(dls, resnet18, metrics=error_rate) . using: . a convolutional neural network (CNN) | the data loaders defined before | the resnet18 as model architecture | the error rate as the metric for the quality (that’s the error rate of the predictions made with the validation set) | a pretrained model (by default) | . and started the fine tuning of the pretrained model with 4 epochs: . learn.fine_tune(4) . The next step was looking at the result and making some data cleaning. Therefor I used the ClassificationInterpretation from fastbook (to plot the confusion matrix and see the top losses) and the ImageClassifierCleaner from fastai to define which images should be deleted or moved to another category: . cleaner = ImageClassifierCleaner(learn) cleaner . Deleting or moving can then be done with: . for idx in cleaner.delete(): cleaner.fns[idx].unlink() for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . Finishing the training . I repeated fine tuning and data cleaning until I got this result from fine tuning (which came with the 3. or 4. run): . . Then I saved the model (architecture and parameters) with the export function of the learner: . learn.export() . which creates the model file export.pkl (this file even includes information about the dataloaders). I downloaded and renamed it for local use. .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/image%20classifier/fastbook/fastai/google%20colab/training/2021/01/05/first-image-classifier.html",
            "relUrl": "/image%20classifier/fastbook/fastai/google%20colab/training/2021/01/05/first-image-classifier.html",
            "date": " • Jan 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Creating this blog",
            "content": "Why do I write this blog? . One really good reason to write this blog is: it improves my understanding of what I’m doing and learning! . But there is more: . As a developer I often feel how important it is for me . to stay focused on my (or my companies) goals | to frequently recap what I’ve done or learned and how succesful it was | to see and remember the progress and not only what’s missing | and to keep the balance between diving deeply into things on one side and reacting to upcoming needs on the other side | . So a great part of this work is just thinking and making decisions. And that’s another reason to write this blog: It should help me to keep myself on this road. . And another important reason is my hope that this blog will one day help others on their way. Sharing content makes learning and development available for everybody. I benefit from this since years. . A GitHub Page for my blog . . This text references a previous version of this blog created with GithHub Pages. It&#39;s still online here To keep things easy I decided to use GitHub Pages for this blog. I created a new git repository on GitHub and choose the main branch as page source and the cayman theme as Jekyll theme. All this can be done in the Settings / Github Pages section of the repository. . In this repository I created a directory structure for my future posts and made my adaptations in the index.md (as the home page of the blog) and _config.yml (the theme configuration). For layout customization I copied the _layouts/default.html from the origin theme repository into my repository and made my (minor) changes. . So I could create my first post (*.md) and reference it in my home page of the blog (index.md). The posts are written in the markdown syntax of the GitHub platform. You can find a short markdown guide here. . When I began to fill my first post with content I changed my procedure. Before that moment I did all editing via browser in the GitHub web site. But then I changed to my local computer: I used my Git Bash to clone the repository and made my editing locally with Visual Studio Code. There is a very nice extension called Markdown All in One which helps you writing pages in the markdown syntax. Now - when ready for publishing - I only have to push my content to the origin repository. The page updates automatically. .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/github%20page/2020/12/26/creating-this-blog.html",
            "relUrl": "/github%20page/2020/12/26/creating-this-blog.html",
            "date": " • Dec 26, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "When my ML learning began",
            "content": "It started with a book . In late 2020 I came across Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard &amp; Sylvain Gugger and I was directly inspired and excited to dive into deep learning. . . Deep Learning, Machine Learning, AI and all the other terms of artifical intelligence had been very unclear to me - even though I’d been working for many years as a software developer. But with this book the door to this domain was opened to me - by authors with long lasting experience in coding and teaching AI. . My coding environment . Following the book coding should take place in Jupyter Notebooks. After looking around for the different ways to get own Jupyter Notebooks running I decided to start with Google Colab for my notebooks. Although there are some issues to keep in mind: . Colab Notebooks differ from the typical Jupyiter Notebook GUI | Google doesn’t garantee access to GPUs (which is highly recommended when training your models). So you can run temporarily into performance issues. | The Colab platform doesn’t support Voila, which will be used for publishing purposes | From the books website you can start any of the books chapters (the book itself is written in Jupyter Notebooks). From there you can copy or create new notebooks and store them in Google Drive. The only prerequisite is a Google Account. That’s all. . That’s the way I started creating and running my very first notebooks. Then I rebuilt the first prepared samples (image classifier and others) coming with the book. . What I learned in this step . Each chapter of the book ends with a questionnaire which helps you checking your learning progress. . I enjoy it. It’s very useful. . Some of the main topics I took from the first chapter: . the main areas of deep learning | from the first artificial neurons to neuronal networks | running the first notebook with Google Colab | understand machine learning as another way (other than writing a program) to let computers do their task - by learning from their experience (= training) | a first idea how training works | predictions coming from input data | different types of models like classification and regression | the meaning of input data and its division into different data sets like a training set used as training input, validation set (or development set) to measure the accuracy of a model and optional a separate test set to test a model with never seen data | jargon: architecture, parameters, labels, epoch, metric, loss, overfitting, hyperparameters, … | a first use of a convolutional neural network (CNN) | the use of pretrained models (and fine-tuning) | image recognition usable for non-image tasks (for example spectograms for sound issues) | .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/fastai/google%20colab/2020/12/20/when-my-ml-starts.html",
            "relUrl": "/fastai/google%20colab/2020/12/20/when-my-ml-starts.html",
            "date": " • Dec 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, . my name is Heike and I am a full stack software developer. . I studied computer science in Kiel, Germany and made my degree in the 90’s. Since that time I mainly worked as a developer in several companies. I touched the areas of logistics, consulting, telecommunication, medicine and currently meteorology. . I started my professional life with coding in C and C++. Then I changed to Java and in the last 2 years also to JavaScript. . Today I am responsible for Desktop Applications written in Java/JavaFX and Backend and Frontend Systems running with Node.js, Express and VueJS. . As a mum I am working part time. I am a fan of life long learning and just started with machine learning and Python in my free time. . . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://baltricks.github.io/my-ml-learning-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://baltricks.github.io/my-ml-learning-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}