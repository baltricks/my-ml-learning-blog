{
  
    
        "post0": {
            "title": "Next",
            "content": "",
            "url": "https://baltricks.github.io/my-ml-learning-blog/2022/01/01/next.html",
            "relUrl": "/2022/01/01/next.html",
            "date": " • Jan 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "My first practice with an image classifier (using fastbook and fastai), Part II",
            "content": "Making predictions from the model . After training and exporting the model I wanted to make some predictions with the model. At first I did it in the training notebook on Google Colab to see how it works. I checked the file with . thisPath = Path() thisPath.ls(file_exts=&#39;.pkl&#39;) . and built a new learner (the inference learner) from the model file: . learn_inf = load_learner(thisPath/&#39;export.pkl&#39;) . I made some single image predictions like . learn_inf.predict(path + &#39;/grizzly/&#39; + &#39;bear1.jpg&#39;) . and got the categories of the model with: . learn_inf.dls.vocab . Building a gui . The next step was to built a little gui - runnable in Jupyter Notebooks - to upload images and make predictions about their class (category). . Following the approach from the book (Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard &amp; Sylvain Gugger) I could built this gui using the IPython widgets. . But I was still working within my training notebook on Google Colab. What I really wanted was a separate notebook without all this training stuff: just my self-trained model and some widgets and actions to get predictions with test images. . Inference in a separate notebook . In the meantime I had installed Anaconda on my local computer and started some Python lessons within local Jupyter Notebooks (I am a coder but a Python newbie). So it was nearby to install the missing packages (fastai and PyTorch) and go on with my prediction gui on my local computer. . But I ran very soon into dependency issues. Finally this does the trick: . I used the Anaconda Navigator to add a new environment and named it ‘fastai’. | I added the fastai and pytorch channels | and installed the pytorch, fastai and fastbook packages | . Now I can run notebooks using fastai in this environment 1. . Then I copied all the neccesary code for inference from the training notebook and created a new local notebook for my gui. I also made a copy of the model file accessible to this new notebook. . And now the gui works. I can upload images and get the classification (also showing its probability)! . . there are still some issues with the gpu/cpu and the path (I’m working with Windows) - but I got it running. &#8617; . |",
            "url": "https://baltricks.github.io/my-ml-learning-blog/image%20classifier/fastbook/fastai/inference/gui/2021/01/07/first-image-classifier-2.html",
            "relUrl": "/image%20classifier/fastbook/fastai/inference/gui/2021/01/07/first-image-classifier-2.html",
            "date": " • Jan 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/jupyter/2021/01/06/test.html",
            "relUrl": "/jupyter/2021/01/06/test.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "My sample notebook post",
            "content": "print(&quot;hello world&quot;) . hello world .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/2021/01/06/my-test.html",
            "relUrl": "/2021/01/06/my-test.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "My first practice with an image classifier (using fastbook and fastai), Part I",
            "content": "Which problem to solve . For my very first practice I followed the book (Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard &amp; Sylvain Gugger) and choose the bear image classifier as my first objective. . Starting with the input data and Google Colab . I used the DuckDuckGo search engine to find proper images in 3 categories as input data and stored them in the subfolders ‘black’, ‘grizzly’ and ‘teddy’. Then I created a new notebook with Google Colab (stored in Google Drive) and set the runtime to GPU. I copied my input data into a data folder on my drive and checked the input path with: . !ls drive/MyDrive/data/images/bears . and after installing and setting up fastbook . !pip install -Uqq fastbook import fastbook fastbook.setup_book() . I also checked the mounted drive . !ls gdrive/MyDrive/data/images/bears . Before continuing let me show the imports I finally needed in my training notebook: . from fastbook import get_image_files, verify_images, Path, DataBlock, ImageBlock, CategoryBlock from fastbook import RandomSplitter, parent_label, Resize, ResizeMethod, RandomResizedCrop, aug_transforms from fastbook import cnn_learner, resnet18, error_rate, load_learner from fastbook import ClassificationInterpretation from fastai.vision.widgets import ImageClassifierCleaner, widgets, PILImage, VBox . Next step was to set my path variable and get the images . path = &#39;gdrive/MyDrive/data/images/bears&#39; fns = get_image_files(path) . After verifying the images and unlinking the failed ones . failed = verify_images(fns) failed.map(Path.unlink) . there were 495 images (in 3 categories) left. . Training a model . First I made some specifications about the input data of the training process: . bears = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . This means that . predictions should be made from images (the independent variable) to categories (the dependent variable) | the items should be taken by the get_image_files function (which is taking a path as argument) | the data set should be splitted randomly into a training and validation set (20% of the data for the validation set; randomly, but always the same sets) | the labeling of the dependent variable (the categories, the y-value) should come from the folder name | and all items (images) should be transformed - here resized - to the same size of 128px | . Then I set the input path and got the data loaders: . dls = bears.dataloaders(path) . Before starting the training I played around with some transformations available for . images (resizing with different methods) and | batches of images (random image variations, the data augmentation) and watched the results printed with the show_batch function of the dataloaders (dls.train for the training set and dls.valid for the validation set). | . Then I followed the recommendation and made this settings: . bears = bears.new( item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = bears.dataloaders(path) . I created the learner: . learn = cnn_learner(dls, resnet18, metrics=error_rate) . using: . a convolutional neural network (CNN) | the data loaders defined before | the resnet18 as model architecture | the error rate as the metric for the quality (that’s the error rate of the predictions made with the validation set) | a pretrained model (by default) | . and started the fine tuning of the pretrained model with 4 epochs: . learn.fine_tune(4) . The next step was looking at the result and making some data cleaning. Therefor I used the ClassificationInterpretation from fastbook (to plot the confusion matrix and see the top losses) and the ImageClassifierCleaner from fastai to define which images should be deleted or moved to another category: . cleaner = ImageClassifierCleaner(learn) cleaner . Deleting or moving can then be done with: . for idx in cleaner.delete(): cleaner.fns[idx].unlink() for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) . Finishing the training . I repeated fine tuning and data cleaning until I got this result from fine tuning (which came with the 3. or 4. run): . . Then I saved the model (architecture and parameters) with the export function of the learner: . learn.export() . which creates the model file export.pkl (this file even includes information about the dataloaders). I downloaded and renamed it for local use. .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/image%20classifier/fastbook/fastai/google%20colab/training/2021/01/05/first-image-classifier.html",
            "relUrl": "/image%20classifier/fastbook/fastai/google%20colab/training/2021/01/05/first-image-classifier.html",
            "date": " • Jan 5, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Creating this blog",
            "content": "Why do I write this blog? . One really good reason to write this blog is: it improves my understanding of what I’m doing and learning! . But there is more: . As a developer I often feel how important it is for me . to stay focused on my (or my companies) goals | to frequently recap what I’ve done or learned and how succesful it was | to see and remember the progress and not only what’s missing | and to keep the balance between diving deeply into things on one side and reacting to upcoming needs on the other side | . So a great part of this work is just thinking and making decisions. And that’s another reason to write this blog: It should help me to keep myself on this road. . And another important reason is my hope that this blog will one day help others on their way. Sharing content makes learning and development available for everybody. I benefit from this since years. . A GitHub Page for my blog . . This text references a previous version of this blog created with GithHub Pages. It&#39;s still online here for demonstration purposes only To keep things easy I decided to use GitHub Pages for this blog. I created a new git repository on GitHub and choose the main branch as page source and the cayman theme as Jekyll theme. All this can be done in the Settings / Github Pages section of the repository. . In this repository I created a directory structure for my future posts and made my adaptations in the index.md (as the home page of the blog) and _config.yml (the theme configuration). For layout customization I copied the _layouts/default.html from the origin theme repository into my repository and made my (minor) changes. . So I could create my first post (*.md) and reference it in my home page of the blog (index.md). The posts are written in the markdown syntax of the GitHub platform. You can find a short markdown guide here. . When I began to fill my first post with content I changed the process. Previously I did all editing via browser in the GitHub web site. But then I changed to my local computer: I used my Git Bash (I’m working on Windows) to clone the repository and made my editing locally with Visual Studio Code. There is a very nice extension called Markdown All in One which helps you writing pages in the markdown syntax. Now - when ready for publishing - I only have to push my content to the origin repository. The page updates automatically. . Changing to fastpages . Some days later when I had built my first model I began thinking about publishing also code or models. I made some experience with Binder and learned how to start a jupyter notebook with Binder (Binder lets you run docker images built from jupyter notebooks). Here is a simple example (don’t worry, it may take some moments when (re)building and launching the image): . . And finally I read about fastpage, a platform that brings blogging and running jupyter notebooks together: It supports jupyter notebooks as blog posts! So you can write a blog post together with runnable code in a jupyter notebook and integrate a button to start the post / notebook itself on a platform like Binder! . These were the main steps I took to migrate my blog to fastpage: . First I followed the instructions to setup my new page | I customized the page in: _config.yml (social links, title, description, show_image) | _pages/about.md (about me) | index.html | _includes/footer.html (copied from the origin minima theme, removed the RSS subscription link) | . | Migrating my posts: copied my former posts into the _posts folder of the new page | changed the names according to the naming convention | added following tags: toc: true / false | layout: post | categories: […] | optional image | . | removed the initial posts | . | Enabled comments for github users: installed the utterances app via https://github.com/apps/utterances (for single repos) | set ‘coments: true’ for all posts | . | . So my page gots also the following features coming with fastpage: . a search page | a tags page showing the contents and categories | pagination in the index page | comments enabled in the posts pages | .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/github%20page/2020/12/26/creating-this-blog.html",
            "relUrl": "/github%20page/2020/12/26/creating-this-blog.html",
            "date": " • Dec 26, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "When my ML learning began",
            "content": "It started with a book . In late 2020 I came across Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD by Jeremy Howard &amp; Sylvain Gugger and I was directly inspired and excited to dive into deep learning. . . Deep Learning, Machine Learning, AI and all the other terms of artifical intelligence had been very unclear to me - even though I’d been working for many years as a software developer. But with this book the door to this domain was opened to me - by authors with long lasting experience in coding and teaching AI. . My coding environment . Following the book coding should take place in Jupyter Notebooks. After looking around for the different ways to get own Jupyter Notebooks running I decided to start with Google Colab for my notebooks. Although there are some issues to keep in mind: . Colab Notebooks differ from the typical Jupyiter Notebook GUI | Google doesn’t garantee access to GPUs (which is highly recommended when training your models). So you can run temporarily into performance issues. | The Colab platform doesn’t support Voila, which will be used for publishing purposes | From the books website you can start any of the books chapters (the book itself is written in Jupyter Notebooks). From there you can copy or create new notebooks and store them in Google Drive. The only prerequisite is a Google Account. That’s all. . That’s the way I started creating and running my very first notebooks. Then I rebuilt the first prepared samples (image classifier and others) coming with the book. . What I learned in this step . Each chapter of the book ends with a questionnaire which helps you checking your learning progress. . I enjoy it. It’s very useful. . Some of the main topics I took from the first chapter: . the main areas of deep learning | from the first artificial neurons to neuronal networks | running the first notebook with Google Colab | understand machine learning as another way (other than writing a program) to let computers do their task - by learning from their experience (= training) | a first idea how training works | predictions coming from input data | different types of models like classification and regression | the meaning of input data and its division into different data sets like a training set used as training input, validation set (or development set) to measure the accuracy of a model and optional a separate test set to test a model with never seen data | jargon: architecture, parameters, labels, epoch, metric, loss, overfitting, hyperparameters, … | a first use of a convolutional neural network (CNN) | the use of pretrained models (and fine-tuning) | image recognition usable for non-image tasks (for example spectograms for sound issues) | .",
            "url": "https://baltricks.github.io/my-ml-learning-blog/fastai/google%20colab/2020/12/20/when-my-ml-starts.html",
            "relUrl": "/fastai/google%20colab/2020/12/20/when-my-ml-starts.html",
            "date": " • Dec 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, . my name is Heike and I am a full stack software developer. . I studied computer science in Kiel, Germany and made my degree in the 90’s. Since that time I worked as a developer in several companies. I touched the areas of logistics, consulting, telecommunication, medicine and currently meteorology. . I started my professional life with coding in C and C++. Then I changed to Java and in the last 2 years also to JavaScript. . Today I am responsible for Desktop Applications written in Java/JavaFX and Backend and Frontend Systems running with Node.js, Express and VueJS. . Since I became a mum (many years ago) I am working part time. I am a fan of life long learning and just started with machine learning and Python in my free time. . . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://baltricks.github.io/my-ml-learning-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://baltricks.github.io/my-ml-learning-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}